# Storynode  
<img align="left" width="400px" src="https://raw.githubusercontent.com/nypl-openaudio/start-here/master/Projects/Images/storynode.png" alt="screenshot of prototype interface with text on right column of screen and a map with some points on it on the left column of the screen">  
#### Short Description  
Stanford Named Entity Recognizer + Transcript = AWESOME MAP  

#### Links and Materials  
[Github Repository](https://github.com/bertspaan/openaudioweekend)  
[Storynode Documentation](https://docs.google.com/document/d/1SSJ7M89HgHJqpwNMHz5rcIWAY5cB8d4HRT_j7q3Dyzo/edit)  

#### Long description   
Wouldn’t it be great if we could see all the locations mentioned in an oral history on a map? We could see not only the connections within one oral history recording, but the connections between multiple recordings in a collection or even across collections. Using Stanford’s Named Entity Recognizer (NER), we identified place names within oral history transcripts and plotted them on a map ~~after first training NER to read NYC street names~~. Working on a user friendly app.  
